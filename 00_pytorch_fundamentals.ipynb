{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ff4e1b7b-ae9c-4b76-b7df-3e90b6068d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3208, -2.2562, -0.5155],\n",
      "        [ 0.6722,  2.3703, -0.7795],\n",
      "        [ 0.1003, -1.1676, -1.1527]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sklearn\n",
    "import matplotlib\n",
    "import torchinfo, torchmetrics\n",
    "\n",
    "# Check PyTorch access (should print out a tensor)\n",
    "print(torch.randn(3, 3))\n",
    "\n",
    "# Check for GPU (should return True)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b74196f-b169-44cf-ad03-a7e77cac878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c441727-0925-4f71-b1dd-5dcd39a8a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random tensor:\n",
      "tensor([[-1.1899,  0.1600, -0.3878],\n",
      "        [-0.5169, -0.7166, -0.3784],\n",
      "        [-1.3063,  0.3814,  1.7909]])\n",
      "CUDA available: False\n",
      "MPS available: True\n",
      "Tensor moved to MPS device: mps:0\n"
     ]
    }
   ],
   "source": [
    "# Crea un tensore casuale\n",
    "x = torch.randn(3, 3)\n",
    "print(f\"Random tensor:\\n{x}\")\n",
    "\n",
    "# Verifica disponibilitÃ  acceleratori\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available() if hasattr(torch.backends, 'mps') else 'MPS module not found'}\")\n",
    "\n",
    "# Prova a utilizzare MPS se disponibile\n",
    "if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    x = x.to(device)\n",
    "    print(f\"Tensor moved to MPS device: {x.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98de0d1e-02bf-4d6e-9943-2a9fa9446e11",
   "metadata": {},
   "source": [
    "## ðŸš¨Durante il corso sostituire CUDA CON MPSðŸš¨\n",
    "\n",
    "`device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")`\n",
    "\n",
    "diventerÃ \n",
    "\n",
    "`device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770215c8-f27f-4a06-8a9f-459e5cfb67c8",
   "metadata": {},
   "source": [
    "### Funzione per rendere universale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a86d5561-87ff-4974-96f9-7ea1a865b686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# Poi usa\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbf38e5-5095-4621-88ff-6992a681322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb657b-0742-473e-8c1a-7bc7e34ceded",
   "metadata": {},
   "source": [
    "## Introduction to Tensors\n",
    "### Creating tensors\n",
    "\n",
    "I tensori PyTotch sono creati usando `torch.Tensor()` [documentazione](https://pytorch.org/docs/stable/tensors.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66632c2a-8228-4cbf-8a9f-feced7113eae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar (non ha dimensione)\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "748e9697-353a-4f2d-bb47-07e726045ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "381df690-9adb-4513-af98-651085d67985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea468f0-c31b-4d1d-88c3-a0a284ad5074",
   "metadata": {},
   "source": [
    "### Vector \n",
    "Array **unidimensionale** di numeri. Rappresenta una grandezza con magnitudine e direzione.\n",
    "**due caratteristiche di un vettore**\n",
    "* **Magnitudine (o Modulo)**: Ãˆ la lunghezza o grandezza del vettore. Rappresenta quanto Ã¨ \"lungo\" il vettore nello spazio. Per un vettore v in uno spazio n-dimensionale, la magnitudine si calcola come la radice quadrata della somma dei quadrati delle sue componenti:\n",
    "$||v|| = âˆš(vâ‚Â² + vâ‚‚Â² + ... + vâ‚™Â²)$\n",
    "* **Direzione**: Ãˆ l'orientamento del vettore nello spazio. Indica verso dove punta il vettore ed Ã¨ determinata dagli angoli che il vettore forma con gli assi di riferimento. Un vettore unitario (con magnitudine 1) nella stessa direzione del vettore originale puÃ² essere ottenuto dividendo il vettore per la sua magnitudine:\n",
    "$Ã» = v / ||v||$\n",
    "\n",
    "Queste due caratteristiche insieme definiscono completamente un vettore: quanto Ã¨ lungo (magnitudine) e verso dove punta (direzione). In PyTorch e nel machine learning, queste proprietÃ  sono fondamentali per molte operazioni, come la normalizzazione dei vettori, il calcolo di distanze e similitudini, e l'ottimizzazione dei gradienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8724238a-094a-4a5f-a9ec-a2592ef92520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad609e44-e173-4301-be55-3f517a1378e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78a278f-c80c-4199-af4e-29c8090c09a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1de38c-8784-4fd5-9596-030adeff246e",
   "metadata": {},
   "source": [
    "### Matrix\n",
    "Array **bidimensionale** di numeri organizzati in righe e colonne. Trasforma vettori in altri vettori.\n",
    "Dimensioni: Una matrice Ã¨ caratterizzata dal numero di righe e colonne (mÃ—n), che definiscono la sua forma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93467766-0ba2-4be5-9c3f-ba0c874ea7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([[7, 8], \n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206ee703-135e-415a-978c-ed362e4c2f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c71c296b-f84c-4905-b11f-da9287642e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce06cd77-cb2b-4bcd-969c-7006b2f6c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe99ad6-a251-4c79-9e46-446998f43b39",
   "metadata": {},
   "source": [
    "## TENSOR\n",
    "Generalizzazione **multidimensionale** di vettori e matrici. Un array n-dimensionale di numeri. Un vettore Ã¨ un tensore di rango 1, una matrice Ã¨ un tensore di rango 2, mentre un tensore puÃ² avere rango 3 o superiore. \n",
    "\n",
    "Esempio di tensore 3D: `[[[1, 2], [3, 4]], [[5, 6], [7, 8]]]`.\n",
    "\n",
    "Nel deep learning, i tensori sono l'unitÃ  fondamentale di dati: immagini (tensori 4D), sequenze di testo (tensori 3D), pesi delle reti (tensori di vari ranghi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72b614a6-33bd-4340-a869-28403e395222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [3, 6, 9],\n",
       "         [2, 3, 4]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1,2,3],\n",
    "                       [3,6,9],\n",
    "                       [2,3,4]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f84d9a3-4d13-4ebd-8572-fec00548316f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e412e863-b745-46c8-bb40-f22ff1e691b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7f90c7e-5552-4823-a7a9-f046a37aac44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [3, 6, 9],\n",
       "        [2, 3, 4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "618194b4-ecbb-42a0-8755-329e8f08584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f56b9f2-1258-42f1-80ef-77371220db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb780f95-6b98-45d2-80d4-2132cb6d91a6",
   "metadata": {},
   "source": [
    "| **Name** | **What is it?** | **Number of dimensions** | **Lower or upper (usually/example)** |\n",
    "|----------|------------|--------------------------|-------------------------------------|\n",
    "| **scalar** | a single number | 0 | Lower (a) | \n",
    "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (y) |\n",
    "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (Q) |\n",
    "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (X) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee94373-081e-4cf3-839b-67c86ab89dd7",
   "metadata": {},
   "source": [
    "## Random Tensors\n",
    "\n",
    "I tensori randomici sono importanti perchÃ¨ il modo in cui le reti neurali imparano, Ã¨ iniziare con un tensore pieno di numeri randomici e poi aggiustano questi numeri per una rappresentazione migliore dei dati.\n",
    "\n",
    "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fc83cc5-68dd-491a-9b45-e81a761047d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1070, 0.0685, 0.2837, 0.4913],\n",
       "        [0.0442, 0.1371, 0.0126, 0.7032],\n",
       "        [0.7393, 0.0785, 0.3405, 0.2403]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor of shape(size) (3,4)\n",
    "\n",
    "random_tensor = torch.rand(3,4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99c9b9d8-c233-4a5a-8ba5-c97a79cde70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e56d3741-d5a7-441e-84da-aea525f43370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65c57a8c-078b-4b9c-b0e0-7f5597403c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with a similar shape to an image\n",
    "random_image_size_tensor = torch.rand(size=(3, 224,224)) # colour channels (R,G,B), height, width, \n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc51ec23-cf95-4fcc-b9c1-631d59241b4c",
   "metadata": {},
   "source": [
    "![tensore](image/00-tensor-shape-example-of-image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a856b6-39b7-4739-980e-088e157120c1",
   "metadata": {},
   "source": [
    "## Zeros and Ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71fe458-303d-4ae1-ba66-c0b8fb64efaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tensor of all zeros (esempio di mask)\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f4674c35-45b6-43f5-84c9-9e129e3363a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7df7df5-dcc8-4754-ae26-136e26a8ac46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ad3aa-c07a-45e4-91f4-968d3e529403",
   "metadata": {},
   "source": [
    "## Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "964899b3-7415-4dc4-867d-647ed1fa2fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arange(start, end, step)\n",
    "one_to_ten = torch.arange(start=0,end=11, step=1)\n",
    "one_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e9393c67-c917-4fb0-abcb-dafdb3ddda26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a tensor like\n",
    "ten_zeroes = torch.zeros_like(input=one_to_ten)\n",
    "ten_zeroes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea756a33-edfa-4364-8fbe-a0ff29c024b3",
   "metadata": {},
   "source": [
    "Il comando `torch.zeros_like(input=one_to_ten)` crea un nuovo tensore con:\n",
    "\n",
    "* La stessa forma (dimensioni) del tensore one_to_ten\n",
    "* Lo stesso tipo di dati (dtype) del tensore one_to_ten\n",
    "* Lo stesso dispositivo (CPU o GPU) del tensore one_to_ten\n",
    "\n",
    "Ma con tutti gli elementi inizializzati a zero.\n",
    "Per esempio:\n",
    "\n",
    "- Se `one_to_ten` Ã¨ un vettore di lunghezza 10, ten_zeroes sarÃ  un vettore di lunghezza 10 contenente solo zeri\n",
    "- Se `one_to_ten` Ã¨ una matrice 3Ã—4, ten_zeroes sarÃ  una matrice 3Ã—4 contenente solo zeri\n",
    "\n",
    "**Questo Ã¨ molto utile quando hai bisogno di creare un tensore con le stesse caratteristiche di un tensore esistente, ma con valori diversi**. Altri metodi simili includono:\n",
    "\n",
    "- `torch.ones_like()`: come zeros_like ma riempie con 1\n",
    "- `torch.randn_like()`: stessa forma ma con valori casuali da una distribuzione normale\n",
    "- `torch.rand_like()`: stessa forma ma con valori casuali uniformi tra 0 e 1\n",
    "- `torch.empty_like()`: stessa forma ma senza inizializzare i valori (per performance)\n",
    "\n",
    "Se invece volessi creare un tensore con la stessa forma ma con un dtype o dispositivo diverso, potresti specificarlo:\n",
    "\n",
    "`pythonten_zeroes = torch.zeros_like(one_to_ten, dtype=torch.float32, device=\"mps\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21fd732-bdf8-44f9-aaec-a8385eb8a701",
   "metadata": {},
   "source": [
    "## Tensor Datatypes\n",
    "- Il `dtype` Ã¨ per la **precision in computing**\n",
    "    - **Precision** is the amount of detail used to describe a number.\n",
    "      The higher the precision value (8, 16, 32), the more detail and hence data\n",
    "      used to express a number. This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use. So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "- `device` what device is the tensor stored on? (usually GPU or CPU)\n",
    "- `require_grad` se vogliamo o meno calcolare i gradienti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "710ffdf2-ada7-4a87-ad42-8048a3b5d363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 tensor (Ã¨ il default)\n",
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                              dtype=None, # What datatype is the tensor (e.g. float32 or float16)\n",
    "                              device=None, # defaults to None, which uses the default tensor type\n",
    "                              requires_grad=False) # if True, operations performed on the tensor are recorded\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "55ea6546-a4bf-4556-a160-5d61066b6d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d4f742b-6431-445e-a0c4-eb39fb318fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], dtype=torch.float16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a8903-797d-4451-b044-c82ba9dfb67b",
   "metadata": {},
   "source": [
    "## Getting Tensor Attributes\n",
    "- check tensor datatype `tensor.dtype`\n",
    "- check tensor shape `tensor.shape`\n",
    "- check tensor device(GPU|TPU) `tensor.device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2aefdff5-601d-461f-87f0-65d89deb5afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7819, 0.0979, 0.0121, 0.7729],\n",
       "        [0.7100, 0.4248, 0.3079, 0.2666],\n",
       "        [0.6290, 0.9386, 0.5207, 0.8704]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6043d575-549a-4ebb-b547-d8bd7f0fcefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7819, 0.0979, 0.0121, 0.7729],\n",
      "        [0.7100, 0.4248, 0.3079, 0.2666],\n",
      "        [0.6290, 0.9386, 0.5207, 0.8704]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "# Find out details about some tensor\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3072ed-6c96-47a6-85bc-a86274401bf3",
   "metadata": {},
   "source": [
    "## Manipulating Tensors (Tensor Operations)\n",
    "Le operazioni sui tensori includono:\n",
    "- Addizioni\n",
    "- Sottrazioni\n",
    "- Moltiplicazioni (element-wise)\n",
    "- Divisioni\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3775f924-acce-4807-ab1f-eb6f18c89ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor and add 10 to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "34d9e988-2963-4641-92ce-2c6042dea7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiply tensor by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9a172944-4f29-4fea-a18d-ca815cf3f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -7])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtract 10\n",
    "tensor -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1923b6c-b531-4968-8341-361b4d9da999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 30])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-built function\n",
    "torch.mul(tensor,10) # torch.add(tensor,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac59d5b-e7ce-4cb3-81eb-38191fe5b491",
   "metadata": {},
   "source": [
    "## Moltiplicazione di Matrici (dot product)\n",
    "La moltiplicazione di matrici Ã¨ un'operazione fondamentale in algebra lineare con importanti applicazioni nel machine learning e deep learning. \n",
    "\n",
    "Le due regole principali sono:\n",
    "\n",
    "**La dimensione interna deve combaciare**:\n",
    "\n",
    "- `(3, 2) @ (3, 2)` won't work\n",
    "- `(2, 3) @ (3, 2)` will work\n",
    "- `(3, 2) @ (2, 3)` will work\n",
    "  \n",
    "**La matriche risultante avrÃ  la forma delle dimensioni esterne**:\n",
    "\n",
    "- `(2, 3) @ (3, 2) -> (2, 2)`\n",
    "- `(3, 2) @ (2, 3) -> (3, 3)`\n",
    "> Note: \"@\" in Python is the symbol for matrix multiplication.\n",
    "\n",
    "![matrix mul](image/matrix_mul.png)\n",
    "[sito math is fun](https://www.mathsisfun.com/algebra/matrix-multiplying.html)\n",
    "\n",
    "Ecco in cosa consiste:\n",
    "**Definizione Formale**\n",
    "Per moltiplicare due matrici A (di dimensione mÃ—n) e B (di dimensione nÃ—p), il risultato sarÃ  una matrice C (di dimensione mÃ—p) dove:\n",
    "$C[i,j] = \\sum_{k=0}^{n-1} A[i,k] Ã— B[k,j]$\n",
    "In parole semplici, ogni elemento $C[i,j]$ della matrice risultante Ã¨ il prodotto scalare della riga i-esima di A con la colonna j-esima di B.\n",
    "\n",
    "**Caratteristiche Chiave**\n",
    "- **Non Ã¨ commutativa**: In generale, AÃ—B â‰  BÃ—A.\n",
    "- **Dimensioni compatibili**: Per poter moltiplicare due matrici, il numero di colonne della prima matrice deve essere uguale al numero di righe della seconda.\n",
    "- **ComplessitÃ  computazionale**: O(nÂ³) per l'algoritmo naÃ¯ve, ma esistono algoritmi piÃ¹ efficienti come Strassen (O(n^2.8)).\n",
    "- **Interpretazione geometrica**: Rappresenta una composizione di trasformazioni lineari.\n",
    "\n",
    "**Esempio Semplice**\n",
    "\n",
    "Per moltiplicare:\n",
    "\n",
    "`A = [[1, 2],[3, 4]]`\n",
    "`B = [[5, 6],[7, 8]]`\n",
    "\n",
    "Il risultato sarÃ :\n",
    "\n",
    "`C = [[19, 22],[43, 50]]`\n",
    "\n",
    "Dove:\n",
    "```\n",
    "C[0,0] = A[0,0]Ã—B[0,0] + A[0,1]Ã—B[1,0] = 1Ã—5 + 2Ã—7 = 19\n",
    "C[0,1] = A[0,0]Ã—B[0,1] + A[0,1]Ã—B[1,1] = 1Ã—6 + 2Ã—8 = 22\n",
    "C[1,0] = A[1,0]Ã—B[0,0] + A[1,1]Ã—B[1,0] = 3Ã—5 + 4Ã—7 = 43\n",
    "C[1,1] = A[1,0]Ã—B[0,1] + A[1,1]Ã—B[1,1] = 3Ã—6 + 4Ã—8 = 50\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cadce100-1435-4439-8113-f94d47404368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "Equals: tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise multiplication\n",
    "\n",
    "print(tensor, \"*\", tensor)\n",
    "print(f\"Equals: {tensor * tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a2b90c4c-b4f9-4363-b36f-4dfcaa6875dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "\n",
    "torch.matmul(tensor,tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db30804c-44c3-4c66-9102-54be77e60ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "07cb446c-59e8-49ce-9297-f72c56133baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matrix multiplication by hand\n",
    "1*1+2*2+3*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a605a782-1cba-4635-8e81-ddc1824e0b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Î¼s, sys: 1e+03 ns, total: 4 Î¼s\n",
      "Wall time: 6.91 Î¼s\n",
      "tensor(14)\n"
     ]
    }
   ],
   "source": [
    "## Differenze di calcolo\n",
    "%time\n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value+= tensor[i] * tensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e481515-0279-4aa1-8ef9-1c65ee558b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 Î¼s, sys: 2 Î¼s, total: 6 Î¼s\n",
      "Wall time: 10 Î¼s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abce0846-e5e3-4401-8eb0-aa776087ab17",
   "metadata": {},
   "source": [
    "## ðŸš¨ Tensors shape error\n",
    "\n",
    "ðŸ’¡ [sito matrix multiplication](http://matrixmultiplication.xyz/) ðŸ’¡, molto simpatico mostra visivamente come viene effettuata un matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "704d2a9c-0887-4965-9776-ca3c33166a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape for matrix multiplication\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]])\n",
    "\n",
    "tensor_B = torch.tensor([[7,10],\n",
    "                       [8,11],\n",
    "                       [9,12]])\n",
    "\n",
    "# torch.mm(tensor_A, tensor_B) # `torch_mm` is = `torch.matmul`\n",
    "# torch.matmul(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cdd27d-324c-4e9e-98cc-fbaf68b994ee",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a **transpose**\n",
    "\n",
    "**transpose** inverte gli assi o le dimensioni di un dato vettore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "929347d0-8d78-4fdc-b466-0bbba27d8935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7, 10],\n",
       "         [ 8, 11],\n",
       "         [ 9, 12]]),\n",
       " torch.Size([3, 2]))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B, tensor_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bce3aa8c-ec62-4aae-98f9-aec16f92b5c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8,  9],\n",
       "         [10, 11, 12]]),\n",
       " torch.Size([2, 3]))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e68c1560-83ff-49a8-a851-332a6cd3d254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
      "New shapes: tensor_A = torch.Size([3, 2]), tensor_B.T = torch.Size([2, 3])\n",
      "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <-- inner dimension must match\n",
      "Ouput:\n",
      "\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "\n",
      "Output shape: torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "# the matrix mult funziona quando il tensor_b ha un transpose\n",
    "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tensor_A = {tensor_A.shape}, tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <-- inner dimension must match\")\n",
    "print(\"Ouput:\\n\")\n",
    "output =  torch.matmul(tensor_A, tensor_B.T)\n",
    "\n",
    "print(output)\n",
    "\n",
    "print(f\"\\nOutput shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac82543-14d4-426c-b905-2fa59f9ac0a0",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc (tensor aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "551a598c-14e7-478d-ac9a-02245db8ca8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0,100,10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e9cb5126-64c2-476d-b90f-0eef34b8e52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find min\n",
    "torch.min(x), x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "32d41872-d89f-4e34-b6b1-0703f02b2284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find max\n",
    "torch.max(x), x.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "025c5244-2d74-4ced-93f8-14ff0c1197ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the mean\n",
    "# NOTA: `torch.mean() rechiede un tensore di tipo float32\n",
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a3a6bbe3-2c96-400e-a0e6-9b6b902abbaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the sum\n",
    "\n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a00fc-f971-4fd4-af51-55916e85bb41",
   "metadata": {},
   "source": [
    "### find argmax e argmin\n",
    "ci tornerÃ  utile quando useremo il layer **softmax**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c66c3c8b-ef18-40fb-9792-012ad60c66a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5deba220-da1c-4be7-9ab2-ced4135655eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9), tensor(9))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trova l'indice del valore piÃ¹ grande\n",
    "torch.argmax(x), x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54cb3f94-5b7b-4cd6-8f77-c3c760126e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "18ff6e0a-c070-479c-ae59-58c752e3adde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trova l'indice del valore piÃ¹ piccolo\n",
    "torch.argmin(x), x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "eba11362-053d-43f3-856d-aff094588fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfb62c2-8458-4b7e-ac67-b3abe7fb9334",
   "metadata": {},
   "source": [
    "## Reshaping stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* **Reshaping** - reshapes an input tensor to a defined shape (**deve essere compatili con la shape iniziale**)\n",
    "* **View** - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* **Stacking** - combine multiple tensors on top of each other (**vstack**) or side by side (**hstack**)\n",
    "* **Squeeze** - remove all `1` dimension from a tensor\n",
    "* **UnSqueeze** - add  a `1` dimension to a target tensor\n",
    "* **Permute** - Return a view of the input with dimension permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c586d13c-a566-4e69-989d-9f1ba5bd8535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's create a tensor\n",
    "import torch\n",
    "x = torch.arange(1.,10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf91d00a-7358-459f-8996-d497a80b1200",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "Rimodella un tensore di input in una forma definita (deve essere compatibile con la forma iniziale, cioÃ¨ il numero totale di elementi deve rimanere invariato)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "026a6beb-861c-4416-8e2d-aa33c32b7cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6f5a8d6a-faf2-4791-afe5-a7974408a926",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.],\n",
       "         [2.],\n",
       "         [3.],\n",
       "         [4.],\n",
       "         [5.],\n",
       "         [6.],\n",
       "         [7.],\n",
       "         [8.],\n",
       "         [9.]]),\n",
       " torch.Size([9, 1]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped_2 = x.reshape(9,1)\n",
    "x_reshaped_2, x_reshaped_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4266795-141d-435f-a96c-14e630c8a8bf",
   "metadata": {},
   "source": [
    "### View\n",
    "Restituisce una vista di un tensore di input con una certa forma ma mantiene la stessa memoria del tensore originale. Le modifiche alla vista modificheranno anche il tensore originale poichÃ© condividono gli stessi dati sottostanti.\n",
    "**view** condivide la memoria con il tensore originale\n",
    "Cambiare `z` cambia `x` in quando una **view** di un tensore condivide la stessa memoria con l'inpunt originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "739b7dc4-f1e2-460e-8adf-eb83fee91b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(1,9)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "fabce061-ccbb-47d0-bd82-8305216ee4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se cambiamo il primo elemento in z, \n",
    "# avverrÃ  lo stesso nel tensore originale\n",
    "z[:,0] = 5\n",
    "z,x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d1c11-fe73-44fe-9ed5-f28f8fc3c746",
   "metadata": {},
   "source": [
    "### Stacking\n",
    "Combina piÃ¹ tensori uno sopra l'altro (vstack) o uno accanto all'altro (hstack). \n",
    "* `dim=0` **vstack**\n",
    "* `dim=1` **hstack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b6ccb296-794d-43c7-9d14-92caf47e7d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim = 0) # vstack\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76970d34-fb22-4fff-9b19-054e94608336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 5., 5., 5.],\n",
       "        [2., 2., 2., 2.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [4., 4., 4., 4.],\n",
       "        [5., 5., 5., 5.],\n",
       "        [6., 6., 6., 6.],\n",
       "        [7., 7., 7., 7.],\n",
       "        [8., 8., 8., 8.],\n",
       "        [9., 9., 9., 9.]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_stacked = torch.stack([x,x,x,x], dim = 1) # hstack\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd17a19-c75b-43fe-a845-2b13464a9e89",
   "metadata": {},
   "source": [
    "### Squeeze & Unsqueeze\n",
    "`torch.squeeze()` remove all single dimensions from a target tensor\n",
    "\n",
    "Rimuove tutte le dimensioni di grandezza 1 da un tensore. Ad esempio, trasformare un tensore di forma `[1, 3, 1, 2]` in uno di forma `[3, 2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d9638f66-ce48-4a2a-9c17-a6a23806ea8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous Shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
      "New Shape: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous Shape: {x_reshaped.shape}\")\n",
    "\n",
    "# Remove extra dimensions\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "print(f\"\\nNew tensor: {x_squeezed}\")\n",
    "print(f\"New Shape: {x_squeezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310b406c-97b2-43d3-9c69-4d86ef6f2b3a",
   "metadata": {},
   "source": [
    "`torch.unsqueeze()` add a single dimensions to a target tensor at specific dim (dimension)\n",
    "\n",
    "Aggiunge una dimensione di grandezza 1 a un tensore target. Ad esempio, trasformare un vettore di forma `[3]` in una matrice di forma `[1, 3]` o `[3, 1]`, a seconda dell'indice specificato.\n",
    "\n",
    "ðŸš€ L'operazione `unsqueeze` Ã¨ molto utile nel deep learning quando hai bisogno di adattare la forma dei tensori per operazioni specifiche, come **aggiungere una dimensione di batch** o una **dimensione di canale per le immagini**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "94c76191-50ba-4599-b38e-fd27d656ee27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
      "Previous Shape: torch.Size([1, 9])\n",
      "\n",
      "New tensor: tensor([[[5.],\n",
      "         [2.],\n",
      "         [3.],\n",
      "         [4.],\n",
      "         [5.],\n",
      "         [6.],\n",
      "         [7.],\n",
      "         [8.],\n",
      "         [9.]]])\n",
      "New Shape: torch.Size([1, 9, 1])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Previous tensor: {x_reshaped}\")\n",
    "print(f\"Previous Shape: {x_reshaped.shape}\")\n",
    "\n",
    "# add extra dimensions\n",
    "x_unsqueezed = x_reshaped.unsqueeze(2)\n",
    "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
    "print(f\"New Shape: {x_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c078a3c-5cf5-41f4-85e3-9c7300988fa2",
   "metadata": {},
   "source": [
    "#### Come leggere le forme dei tensori\n",
    "ad esempio `torch.Size([1, 9, 1])` Ã¨ un tensore 3D con:\n",
    "\n",
    "\n",
    "* 1 \"blocco\"\n",
    "* Contenente 9 \"righe\"\n",
    "* Ciascuna \"riga\" ha 1 solo valore\n",
    "\n",
    "**Suggerimento visivo:**\n",
    "Per un tensore di forma `[a, b, c, ...]`:\n",
    "\n",
    "* Pensa a a come al numero di \"scatole\"\n",
    "* Ogni scatola contiene b \"righe\"\n",
    "* Ogni riga contiene c \"colonne\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d143b0d-8de0-4c8b-8b14-3013aea0b4da",
   "metadata": {},
   "source": [
    "### Permute\n",
    "`torch.permute` - rearrages the dimensions of a target tensor in a specified order\n",
    "\n",
    "Restituisce una **vista** (condivide la stessa memoria) del tensore di input con le dimensioni permutate (scambiate) in un certo modo. Ad esempio, trasformare un tensore di forma `[64, 3, 224, 224]` (**batch, canali, altezza, larghezza**) in `[64, 224, 224, 3]` per cambiare l'ordine delle dimensioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "887e5860-e562-4508-8150-de9a13117dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "x_original = torch.rand(size=(224,224,3)) # [height, width, colour_channels\n",
    "\n",
    "# permute the original tensor to rearrrange the axis (or dim) order\n",
    "\n",
    "x_permuted = x_original.permute(2,0,1) # shifts axis 0->1, 1->2, 2->0\n",
    "\n",
    "\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc4cd64-8127-45d4-b832-e0dd6379dc60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
